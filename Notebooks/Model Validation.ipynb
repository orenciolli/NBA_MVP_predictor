{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6feb851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#engineering\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#prediction\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#validation\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54314297",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.read_csv('data/nba_player_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c0a534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full['pts w/l'] = full['PTS'] * full['W/L%']\n",
    "full['usage w/l'] = full['USG%'] * full['W/L%']\n",
    "full['bpm w/l'] = full['BPM'] * full['W/L%']\n",
    "full['per w/l'] = full['PER'] * full['W/L%']\n",
    "full['ws w/l'] = full['WS'] * full['W/L%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4664406",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant = ['G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P',\n",
    "       '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB',\n",
    "       'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'W', 'L', 'W/L%',\n",
    "       'PS/G', 'PA/G', 'SRS', 'PER', 'TS%', '3PAr', 'FTr',\n",
    "       'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS',\n",
    "       'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'pts w/l',\n",
    "        'usage w/l', 'bpm w/l', 'per w/l', 'ws w/l']\n",
    "corrs = []\n",
    "for col in quant:\n",
    "    correlation = full['Share'].corr(full[col])\n",
    "    corrs.append((col, correlation))\n",
    "corrs = sorted(corrs, key = lambda x: x[1], reverse = True)\n",
    "correlated = [tup[0] for tup in corrs[:15]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8e58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(year, df):\n",
    "    training = df[df['Year'] != year]\n",
    "    x_train = training[correlated]\n",
    "    y_train = training['Share']\n",
    "    \n",
    "    test = df[df['Year'] == year]\n",
    "    x_test = test[correlated]\n",
    "    y_test = test['Share']\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c6f7882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvp_table(df, regressor):\n",
    "    predicted_winners = [name_mvp(predict_share(year, df, regressor)) \n",
    "         for year in df.sort_values(by = 'Year')['Year'].unique()]\n",
    "    \n",
    "    winners = df[df['Rank'] == '1'].reset_index().sort_values(by = 'Year')\n",
    "    final = winners[['Year', 'Player']].rename({'Player': 'Actual MVP'}, axis = 1)\n",
    "    final['Predicted MVP'] = predicted_winners\n",
    "    \n",
    "    final['Correct'] = final['Actual MVP'] == final['Predicted MVP']\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "480562bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_mvp(df):\n",
    "    return df.sort_values(by = 'Predicted share', ascending = False)['Player'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba7ad6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_share(year, df, pred):\n",
    "    X_train, Y_train, X_test, Y_test = get_train(year, df)\n",
    "    players = df['Player']\n",
    "    \n",
    "    pred.fit(X_train, Y_train)\n",
    "    predictions = pred.predict(X_test)\n",
    "    \n",
    "    out = X_test.copy()\n",
    "    out['Actual share'] = Y_test\n",
    "    out['Predicted share'] = predictions\n",
    "    out['Player'] = players\n",
    "    return out[['Actual share', 'Predicted share', 'Player']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b4c5a96",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dl/8n__h2151hd3n3gtfckwb75w0000gn/T/ipykernel_96788/1420289804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             predicted = mvp_table(full, XGBRegressor(learning_rate = rate, max_depth = d, n_estimators = n,\n\u001b[0m\u001b[1;32m     11\u001b[0m                                                     subsample = 1, colsample_bytree = 1))\n\u001b[1;32m     12\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"learning rate {rate}, depth {d}, estimators {n}: {predicted['Correct'].mean()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/dl/8n__h2151hd3n3gtfckwb75w0000gn/T/ipykernel_96788/3832145047.py\u001b[0m in \u001b[0;36mmvp_table\u001b[0;34m(df, regressor)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmvp_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     predicted_winners = [name_mvp(predict_share(year, df, regressor)) \n\u001b[0m\u001b[1;32m      3\u001b[0m          for year in df.sort_values(by = 'Year')['Year'].unique()]\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwinners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rank'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Year'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/dl/8n__h2151hd3n3gtfckwb75w0000gn/T/ipykernel_96788/3832145047.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmvp_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     predicted_winners = [name_mvp(predict_share(year, df, regressor)) \n\u001b[0m\u001b[1;32m      3\u001b[0m          for year in df.sort_values(by = 'Year')['Year'].unique()]\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwinners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rank'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Year'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/dl/8n__h2151hd3n3gtfckwb75w0000gn/T/ipykernel_96788/3314295232.py\u001b[0m in \u001b[0;36mpredict_share\u001b[0;34m(year, df, pred)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Player'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         )\n\u001b[0;32m--> 961\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1733\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1734\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn = [0.00275, 0.005, 0.02, 0.1, 0.3, 0.5, 0.8]\n",
    "depth = [2, 4, 6, 8, 10, 12, 15, 20, 25]\n",
    "estimators = [10, 15, 20, 30, 50, 70, 100, 200]\n",
    "\n",
    "results = []\n",
    "\n",
    "for rate in learn:\n",
    "    for d in depth:\n",
    "        for n in estimators:\n",
    "            predicted = mvp_table(full, XGBRegressor(learning_rate = rate, max_depth = d, n_estimators = n,\n",
    "                                                    subsample = 1, colsample_bytree = 1))\n",
    "            results.append(f\"learning rate {rate}, depth {d}, estimators {n}: {predicted['Correct'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2e1754a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learning rate 0.00275, depth 2, estimators 10: 0.5581395348837209',\n",
       " 'learning rate 0.00275, depth 2, estimators 15: 0.5581395348837209',\n",
       " 'learning rate 0.00275, depth 2, estimators 20: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 2, estimators 30: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 2, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 2, estimators 70: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 2, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 2, estimators 200: 0.627906976744186',\n",
       " 'learning rate 0.00275, depth 4, estimators 10: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 4, estimators 15: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 4, estimators 20: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 4, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 4, estimators 50: 0.5581395348837209',\n",
       " 'learning rate 0.00275, depth 4, estimators 70: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 4, estimators 100: 0.5581395348837209',\n",
       " 'learning rate 0.00275, depth 4, estimators 200: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 6, estimators 10: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 6, estimators 15: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 6, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 6, estimators 30: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 6, estimators 50: 0.5348837209302325',\n",
       " 'learning rate 0.00275, depth 6, estimators 70: 0.5581395348837209',\n",
       " 'learning rate 0.00275, depth 6, estimators 100: 0.5348837209302325',\n",
       " 'learning rate 0.00275, depth 6, estimators 200: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 8, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.00275, depth 8, estimators 15: 0.627906976744186',\n",
       " 'learning rate 0.00275, depth 8, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 8, estimators 30: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 8, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 8, estimators 70: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 8, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 8, estimators 200: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 10, estimators 10: 0.6511627906976745',\n",
       " 'learning rate 0.00275, depth 10, estimators 15: 0.6511627906976745',\n",
       " 'learning rate 0.00275, depth 10, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.00275, depth 10, estimators 30: 0.6511627906976745',\n",
       " 'learning rate 0.00275, depth 10, estimators 50: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 10, estimators 70: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 10, estimators 100: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 10, estimators 200: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 12, estimators 10: 0.6511627906976745',\n",
       " 'learning rate 0.00275, depth 12, estimators 15: 0.6511627906976745',\n",
       " 'learning rate 0.00275, depth 12, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.00275, depth 12, estimators 30: 0.627906976744186',\n",
       " 'learning rate 0.00275, depth 12, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 12, estimators 70: 0.5581395348837209',\n",
       " 'learning rate 0.00275, depth 12, estimators 100: 0.6046511627906976',\n",
       " 'learning rate 0.00275, depth 12, estimators 200: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 15, estimators 10: 0.6511627906976745',\n",
       " 'learning rate 0.00275, depth 15, estimators 15: 0.6511627906976745',\n",
       " 'learning rate 0.00275, depth 15, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.00275, depth 15, estimators 30: 0.627906976744186',\n",
       " 'learning rate 0.00275, depth 15, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 15, estimators 70: 0.5581395348837209',\n",
       " 'learning rate 0.00275, depth 15, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 15, estimators 200: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 20, estimators 10: 0.6511627906976745',\n",
       " 'learning rate 0.00275, depth 20, estimators 15: 0.6511627906976745',\n",
       " 'learning rate 0.00275, depth 20, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.00275, depth 20, estimators 30: 0.627906976744186',\n",
       " 'learning rate 0.00275, depth 20, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 20, estimators 70: 0.5581395348837209',\n",
       " 'learning rate 0.00275, depth 20, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 20, estimators 200: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 25, estimators 10: 0.6511627906976745',\n",
       " 'learning rate 0.00275, depth 25, estimators 15: 0.6511627906976745',\n",
       " 'learning rate 0.00275, depth 25, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.00275, depth 25, estimators 30: 0.627906976744186',\n",
       " 'learning rate 0.00275, depth 25, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 25, estimators 70: 0.5581395348837209',\n",
       " 'learning rate 0.00275, depth 25, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.00275, depth 25, estimators 200: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 2, estimators 10: 0.5581395348837209',\n",
       " 'learning rate 0.005, depth 2, estimators 15: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 2, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 2, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 2, estimators 50: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 2, estimators 70: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 2, estimators 100: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 2, estimators 200: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 4, estimators 10: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 4, estimators 15: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 4, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 4, estimators 30: 0.5581395348837209',\n",
       " 'learning rate 0.005, depth 4, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 4, estimators 70: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 4, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 4, estimators 200: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 6, estimators 10: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 6, estimators 15: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 6, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 6, estimators 30: 0.5348837209302325',\n",
       " 'learning rate 0.005, depth 6, estimators 50: 0.5348837209302325',\n",
       " 'learning rate 0.005, depth 6, estimators 70: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 6, estimators 100: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 6, estimators 200: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 8, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 8, estimators 15: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 8, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 8, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 8, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 8, estimators 70: 0.5581395348837209',\n",
       " 'learning rate 0.005, depth 8, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 8, estimators 200: 0.6511627906976745',\n",
       " 'learning rate 0.005, depth 10, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 10, estimators 15: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 10, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 10, estimators 30: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 10, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 10, estimators 70: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 10, estimators 100: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 10, estimators 200: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 12, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 12, estimators 15: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 12, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 12, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 12, estimators 50: 0.5581395348837209',\n",
       " 'learning rate 0.005, depth 12, estimators 70: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 12, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 12, estimators 200: 0.6046511627906976',\n",
       " 'learning rate 0.005, depth 15, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 15, estimators 15: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 15, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 15, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 15, estimators 50: 0.5581395348837209',\n",
       " 'learning rate 0.005, depth 15, estimators 70: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 15, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 15, estimators 200: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 20, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 20, estimators 15: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 20, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 20, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 20, estimators 50: 0.5581395348837209',\n",
       " 'learning rate 0.005, depth 20, estimators 70: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 20, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 20, estimators 200: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 25, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 25, estimators 15: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 25, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.005, depth 25, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 25, estimators 50: 0.5581395348837209',\n",
       " 'learning rate 0.005, depth 25, estimators 70: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 25, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.005, depth 25, estimators 200: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 2, estimators 10: 0.6046511627906976',\n",
       " 'learning rate 0.02, depth 2, estimators 15: 0.6046511627906976',\n",
       " 'learning rate 0.02, depth 2, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.02, depth 2, estimators 30: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 2, estimators 50: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 2, estimators 70: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 2, estimators 100: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 2, estimators 200: 0.6046511627906976',\n",
       " 'learning rate 0.02, depth 4, estimators 10: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 4, estimators 15: 0.6046511627906976',\n",
       " 'learning rate 0.02, depth 4, estimators 20: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 4, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 4, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 4, estimators 70: 0.6046511627906976',\n",
       " 'learning rate 0.02, depth 4, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 4, estimators 200: 0.6511627906976745',\n",
       " 'learning rate 0.02, depth 6, estimators 10: 0.5581395348837209',\n",
       " 'learning rate 0.02, depth 6, estimators 15: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 6, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.02, depth 6, estimators 30: 0.6046511627906976',\n",
       " 'learning rate 0.02, depth 6, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 6, estimators 70: 0.5581395348837209',\n",
       " 'learning rate 0.02, depth 6, estimators 100: 0.5581395348837209',\n",
       " 'learning rate 0.02, depth 6, estimators 200: 0.5581395348837209',\n",
       " 'learning rate 0.02, depth 8, estimators 10: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 8, estimators 15: 0.5581395348837209',\n",
       " 'learning rate 0.02, depth 8, estimators 20: 0.5581395348837209',\n",
       " 'learning rate 0.02, depth 8, estimators 30: 0.6046511627906976',\n",
       " 'learning rate 0.02, depth 8, estimators 50: 0.6744186046511628',\n",
       " 'learning rate 0.02, depth 8, estimators 70: 0.6046511627906976',\n",
       " 'learning rate 0.02, depth 8, estimators 100: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 8, estimators 200: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 10, estimators 10: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 10, estimators 15: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 10, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.02, depth 10, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 10, estimators 50: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 10, estimators 70: 0.6511627906976745',\n",
       " 'learning rate 0.02, depth 10, estimators 100: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 10, estimators 200: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 12, estimators 10: 0.5581395348837209',\n",
       " 'learning rate 0.02, depth 12, estimators 15: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 12, estimators 20: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 12, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 12, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 12, estimators 70: 0.6511627906976745',\n",
       " 'learning rate 0.02, depth 12, estimators 100: 0.6511627906976745',\n",
       " 'learning rate 0.02, depth 12, estimators 200: 0.6511627906976745',\n",
       " 'learning rate 0.02, depth 15, estimators 10: 0.5581395348837209',\n",
       " 'learning rate 0.02, depth 15, estimators 15: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 15, estimators 20: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 15, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 15, estimators 50: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 15, estimators 70: 0.6744186046511628',\n",
       " 'learning rate 0.02, depth 15, estimators 100: 0.6744186046511628',\n",
       " 'learning rate 0.02, depth 15, estimators 200: 0.6744186046511628',\n",
       " 'learning rate 0.02, depth 20, estimators 10: 0.5581395348837209',\n",
       " 'learning rate 0.02, depth 20, estimators 15: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 20, estimators 20: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 20, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 20, estimators 50: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 20, estimators 70: 0.6744186046511628',\n",
       " 'learning rate 0.02, depth 20, estimators 100: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 20, estimators 200: 0.6511627906976745',\n",
       " 'learning rate 0.02, depth 25, estimators 10: 0.5581395348837209',\n",
       " 'learning rate 0.02, depth 25, estimators 15: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 25, estimators 20: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 25, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.02, depth 25, estimators 50: 0.627906976744186',\n",
       " 'learning rate 0.02, depth 25, estimators 70: 0.6744186046511628',\n",
       " 'learning rate 0.02, depth 25, estimators 100: 0.6511627906976745',\n",
       " 'learning rate 0.02, depth 25, estimators 200: 0.6744186046511628',\n",
       " 'learning rate 0.1, depth 2, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 2, estimators 15: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 2, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 2, estimators 30: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 2, estimators 50: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 2, estimators 70: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 2, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.1, depth 2, estimators 200: 0.5813953488372093',\n",
       " 'learning rate 0.1, depth 4, estimators 10: 0.5813953488372093',\n",
       " 'learning rate 0.1, depth 4, estimators 15: 0.5813953488372093',\n",
       " 'learning rate 0.1, depth 4, estimators 20: 0.5813953488372093',\n",
       " 'learning rate 0.1, depth 4, estimators 30: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 4, estimators 50: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 4, estimators 70: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 4, estimators 100: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 4, estimators 200: 0.6744186046511628',\n",
       " 'learning rate 0.1, depth 6, estimators 10: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 6, estimators 15: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 6, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 6, estimators 30: 0.5581395348837209',\n",
       " 'learning rate 0.1, depth 6, estimators 50: 0.5813953488372093',\n",
       " 'learning rate 0.1, depth 6, estimators 70: 0.5813953488372093',\n",
       " 'learning rate 0.1, depth 6, estimators 100: 0.5813953488372093',\n",
       " 'learning rate 0.1, depth 6, estimators 200: 0.5813953488372093',\n",
       " 'learning rate 0.1, depth 8, estimators 10: 0.6744186046511628',\n",
       " 'learning rate 0.1, depth 8, estimators 15: 0.6511627906976745',\n",
       " 'learning rate 0.1, depth 8, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 8, estimators 30: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 8, estimators 50: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 8, estimators 70: 0.6511627906976745',\n",
       " 'learning rate 0.1, depth 8, estimators 100: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 8, estimators 200: 0.6511627906976745',\n",
       " 'learning rate 0.1, depth 10, estimators 10: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 10, estimators 15: 0.6511627906976745',\n",
       " 'learning rate 0.1, depth 10, estimators 20: 0.6511627906976745',\n",
       " 'learning rate 0.1, depth 10, estimators 30: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 10, estimators 50: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 10, estimators 70: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 10, estimators 100: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 10, estimators 200: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 12, estimators 10: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 12, estimators 15: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 12, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 12, estimators 30: 0.5813953488372093',\n",
       " 'learning rate 0.1, depth 12, estimators 50: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 12, estimators 70: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 12, estimators 100: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 12, estimators 200: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 15, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 15, estimators 15: 0.6511627906976745',\n",
       " 'learning rate 0.1, depth 15, estimators 20: 0.6511627906976745',\n",
       " 'learning rate 0.1, depth 15, estimators 30: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 15, estimators 50: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 15, estimators 70: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 15, estimators 100: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 15, estimators 200: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 20, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 20, estimators 15: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 20, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 20, estimators 30: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 20, estimators 50: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 20, estimators 70: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 20, estimators 100: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 20, estimators 200: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 25, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 25, estimators 15: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 25, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.1, depth 25, estimators 30: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 25, estimators 50: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 25, estimators 70: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 25, estimators 100: 0.6046511627906976',\n",
       " 'learning rate 0.1, depth 25, estimators 200: 0.6046511627906976',\n",
       " 'learning rate 0.3, depth 2, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.3, depth 2, estimators 15: 0.627906976744186',\n",
       " 'learning rate 0.3, depth 2, estimators 20: 0.627906976744186',\n",
       " 'learning rate 0.3, depth 2, estimators 30: 0.6744186046511628',\n",
       " 'learning rate 0.3, depth 2, estimators 50: 0.627906976744186',\n",
       " 'learning rate 0.3, depth 2, estimators 70: 0.627906976744186',\n",
       " 'learning rate 0.3, depth 2, estimators 100: 0.627906976744186',\n",
       " 'learning rate 0.3, depth 2, estimators 200: 0.627906976744186',\n",
       " 'learning rate 0.3, depth 4, estimators 10: 0.6046511627906976',\n",
       " 'learning rate 0.3, depth 4, estimators 15: 0.5813953488372093',\n",
       " 'learning rate 0.3, depth 4, estimators 20: 0.5581395348837209',\n",
       " 'learning rate 0.3, depth 4, estimators 30: 0.5581395348837209',\n",
       " 'learning rate 0.3, depth 4, estimators 50: 0.5581395348837209',\n",
       " 'learning rate 0.3, depth 4, estimators 70: 0.5581395348837209',\n",
       " 'learning rate 0.3, depth 4, estimators 100: 0.5581395348837209',\n",
       " 'learning rate 0.3, depth 4, estimators 200: 0.5581395348837209',\n",
       " 'learning rate 0.3, depth 6, estimators 10: 0.627906976744186',\n",
       " 'learning rate 0.3, depth 6, estimators 15: 0.6046511627906976',\n",
       " 'learning rate 0.3, depth 6, estimators 20: 0.6046511627906976',\n",
       " 'learning rate 0.3, depth 6, estimators 30: 0.6046511627906976',\n",
       " 'learning rate 0.3, depth 6, estimators 50: 0.6046511627906976']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe4f579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
